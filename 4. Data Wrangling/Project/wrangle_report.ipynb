{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Wrangle Report</center></h1>\n",
    "<h3><center> by Kueh Seow Teck</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I will be wragling ï¼ˆand analyzing and visualizing) a dataset from the tweet archive of a popular Twitter account user @dog_rates, also known as WeRateDogs. The account features dogs along with humorous comments. The tweet also include a rating for these dogs which always ahave a denominator of 10. This Twitter account garners about 8.8 mullion followers up to date.\n",
    "\n",
    "The dataset which I will be using for this project is sent by WeRateDogs to Udacity via email which includes 5000+ tweets with an end date of August 1,2017. Other than that, I will also be querying extra data (retweets and replies numbers) from their account through the Twitter API. Last but not least, Udacity also provided me with image prediction results derived from neutral network through the input of the dog images from these tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Below are the Python libraries I have used for this project:\n",
    "    - `pandas`: importing flat files and wrangling the tables\n",
    "    - `numpy`: running mathmatical operations\n",
    "    - `requests`: use for making HTTP request to download the image predictions results in the form of .tsv file from a URL.\n",
    "    - `os`: navigate through the directories\n",
    "    - `json`: for reading json data collected in .txt file through Twitter API\n",
    "    - `tweepy`: for accessing Twitter API\n",
    "    - `matplotlib.pyplot`: for data visualizations\n",
    "    - `re`: for regular expressions\n",
    "2. Other than the Python libraries, I have also registered myself a Twitter account and setup a developer account. From there, i created an app in order to generate the Consumer API keys, and Access Token and Access Token Secret which will be use to access the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks for this project:\n",
    "1. Data wrangling, consisting of :\n",
    "    - Gathering data\n",
    "    - Accessing data\n",
    "    - Cleaning data\n",
    "\n",
    "    **Note**: Data wrangling process is completed in the Jupyter notebook: `wrangle_act.ipynb`\n",
    "3. Analyzing and visualizing the wrangled data\n",
    "4. Create two written reports:\n",
    "    - `wrangle_report.pdf`: Describe my wrangling efforts\n",
    "    - `act_report.pdf`: Communicate my insigts and displays the visualizations(s) produced from my wrangled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data gathering process involving loading data from three different sources.\n",
    "Below are the details of the data gathering process:\n",
    "\n",
    "I gathered the first dataset by manually uploading the twitter-archive-enhanced.csv file provided by Udacity into my Jupyter workspace in the Udacity Classroom. I then loaded the .csv file into Jupyter notebook using the Python library.\n",
    "\n",
    "For the second dataset, I was requested to download the file from Udacity's server from the URL https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv by using the Requests library. After that, I load the .tsv file into my Jupyter workspace using Python library.\n",
    "\n",
    "Lastly, I gathered the third dataset from WeRateDogs Twitter archive using Tweepy and stored them in a JSON file (tweet_json.txt). Then, I read the file using JSON library and load it as a dictionary before converting it to a Pandas dataframe object by using Pandas library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the initial accessment of the data visually by using head() and sample() functions. After identified some of the key issues, I dive deeper through programatic accessment using the info(), value_counts() etc functions.\n",
    "\n",
    "I identified and classified issues into two groups: data quality issues and data tidiness issues:\n",
    "\n",
    "**Quality Issues**\n",
    "\n",
    "Here is a list of data quality issues I have identified from the three datasets:\n",
    "##### `twitter_archive_enhanced` table\n",
    "- retweeted_user_id and retweeted_status_id columns: Replies and retweets among the entries\n",
    "- expanded_urls column: 59 Missing expanded_urls\n",
    "- tweet_id column: tweet_id is an integer instead of a string\n",
    "- timestamp column: timestamp is a string instead of datetime\n",
    "- rating_denominator column: rating_denominator less/more than 10 (should be standardize to 10)\n",
    "- name column: Over 745 tweets have no name with 55 named 'a'/'an'and some with really short names; Below are the detailed observations from these rows\n",
    " - Bo, Jo, Ed, JD, Mo are actual dog names\n",
    " - The actual name of the dog with the name Al is actually Al Cabone\n",
    " - The actual name of the dog with the name O is actually O'Malley\n",
    " - Below are some of the corrected dog names extracted manually from the text column of the rows with name a/an: (Example: Index name)\n",
    "    - 1955 Kip\n",
    "    - 2034 Jacob\n",
    "    - 2066 Rufus\n",
    "    - 2116 Spork\n",
    "    - 2125 Cherokee\n",
    "    - 2128 Hemry\n",
    "    - 2146 Alphred\n",
    "    - 2161 Alfredo\n",
    "    - 2191 Leroi\n",
    "    - 2218 Chuk\n",
    "    - 2235 Alfonso\n",
    "    - 2249 Cheryl\n",
    "    - 2255 Jessiga\n",
    "    - 2264 Klint\n",
    "    - 2273 Kohl\n",
    "    - 2287 Daryl\n",
    "    - 2304 Pepe\n",
    "    - 2311 Octaviath\n",
    "    - 2314 Johm\n",
    "    - 2204 Berta\n",
    "- source column: long string; can be simplified and data type is string instead of categorical\n",
    "- pupper,puppo,floofer and doggo columns:Around 1976 tweets having no dog stage data (all four stages showing 'None')\n",
    "- rating_numerator and rating_denominator columns: these columns are not extracted properly from text\n",
    "\n",
    "##### `image_predictions` table\n",
    "- tweet_id column: tweet_id is integer instead of string\n",
    "- p1,p2,p3 columns: dog breeds have inconsistent lower/uppercase\n",
    "- img_num: img_num is float instead of integer\n",
    "- p1, p1_conf columns:I only want to keep columns with highest confidence level\n",
    "\n",
    "**Tidiness Issues**\n",
    "##### `tweet_json` table\n",
    "- Various stages of dog (ie doggo, floofer, pupper,puppo) in the `twitter_archieve_enhanced` table should be one column\n",
    "\n",
    "##### `twitter_archive_enhanced` table\n",
    "- `tweet_json` and `image_predictions` should be merged with the `twitter_arvhive_enhanced` table as they are one observation unit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data wrangling process is complete. The final cleaned data is stored in the file `twitter_archive_master.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
